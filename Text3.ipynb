{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_dataset() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[0;32m----> 2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnyt_train.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m dataset_val \u001B[38;5;241m=\u001B[39m load_dataset(data_files\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnyt_train.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mkeys())\n",
      "\u001B[0;31mTypeError\u001B[0m: load_dataset() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "from nlp import load_dataset\n",
    "dataset = load_dataset('csv', data_files='nyt_train.csv', split='train')\n",
    "dataset_val = load_dataset('csv', data_files='nyt_train.csv', split='validation')\n",
    "print(dataset.keys())\n",
    "print(\"Size of train dataset: \", dataset['train'].shape)\n",
    "print(\"Size of Validation dataset: \", dataset_val['validation'].shape)\n",
    "## Look at Sample Examples\n",
    "print(dataset['train'][0].keys())\n",
    "print(\" Example of text: \", dataset['train'][0]['maintext'])\n",
    "print(\" Example of Summary: \", dataset['train'][0]['title'])\n",
    "## Estimate Average Length of Text and Summary\n",
    "tiny_dataset = dataset['train'].select(list(range(0, 100)))\n",
    "text_len = []\n",
    "summary_len=[]\n",
    "for i in range(len(tiny_dataset)):\n",
    "    example = tiny_dataset[i]\n",
    "    text_example = example['maintext']\n",
    "    text_example = text_example.replace('\\n','')\n",
    "    text_words = text_example.split()\n",
    "    text_len.append(len(text_words))\n",
    "    summary_example = example['title']\n",
    "    summary_example = summary_example.replace('\\n','')\n",
    "    summary_words = summary_example.split()\n",
    "    summary_len.append(len(summary_words))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(text_len)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}