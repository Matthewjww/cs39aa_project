{"authors": ["Vivian Wang", "The New York Times", "Lynsey Chutel"], "date_download": "2022-10-25 23:50:56", "date_modify": "2022-10-25 23:50:56", "date_publish": "2021-10-26 11:00:21", "description": null, "filename": "live_2021_10_26_business_news-business-stock-market_hong-kongs-quarantine-rules-among-the-tightest-in-world-are-getting-even-tighter_1666741856.html", "image_url": "https://static01.nyt.com/images/2021/10/26/world/26virus-briefing-hong-kong-exemptions/26virus-briefing-hong-kong-exemptions-facebookJumbo.jpg", "language": "en", "localpath": "/Users/matthewwhite/news-please-repo//data/2022/10/25/nytimes.com/live_2021_10_26_business_news-business-stock-market_hong-kongs-quarantine-rules-among-the-tightest-in-world-are-getting-even-tighter_1666741856.html", "title": "YouTube, Snap and TikTok executives take their turn answering to Washington.", "title_page": "YouTube, Snap and TikTok executives take their turn answering to Washington. - The New York Times", "title_rss": "NULL", "source_domain": "nytimes.com", "maintext": "A bipartisan group of senators questioned executives from YouTube, Snap and TikTok about software driving children and teenagers to harmful posts within their platforms, as well as data privacy and transparency.\n“Everything that you do is to add users, especially kids, and keep them on your apps for longer. I understand from your testimony that your defense is, ‘We’re not Facebook. We’re different, and we’re different from each other.’ Being different from Facebook is not a defense. That bar is in the gutter.” “It seems like every day that I hear stories about kids and teens who are suffering after interacting with TikTok, YouTube and Snapchat. Kids as young as nine have died doing viral challenges on TikTok. And we’ve seen teen girls lured into inappropriate sexual relationships with predators on Snapchat. You’re parents, how can you allow this?” “The question is whether you provide external independent researchers with access to your algorithms, and data sets and data privacy?” “We regularly partner with experts, for example, in child development, mental health to work —” “But they are experts chosen by you — if somebody independent came to you and wanted that access, yes or no, would you permit it?” “Senator, it would depend on the details, but we are always looking to partner with experts in these important fields.” “Well, I’m going to cite the difference between your response, and Mr. Beckerman and Ms. Stout’s, which indicates certainly a strong hesitancy, if not resistance, to providing access.” “Why does TikTok and Bytedance and Douyin need that information on our children?” “Senator, TikTok is an entertainment platform where people watch and enjoy, and create short-form videos. It’s about uplifting, entertaining content. People love it, and I disagree —” “That is —” “With the characterization of the way —” “That is it from the positive. But there’s also a negative, and the negative is that you are building a profile, a virtual you, of our children because of the data that you’re collecting.” “So I have had a case right in my state, two cases actually, of young people who got drugs through Snap. Will you commit to providing more information about the automated tool Snap uses to proactively search for illegal drug-related content as the parents ask?” “I want to make clear we are absolutely determined to remove all drug dealers from Snapchat. And we have deployed proactive detection measures to get ahead of what the drug dealers are doing. They are constantly evading our tactics, not just on Snapchat, but on every platform. We’ve also stepped up our work with law enforcement.”\nWASHINGTON — Lawmakers have hammered Facebook for weeks about how they say the platform harms its youngest users. But they showed Tuesday that their concerns about data privacy, harmful posts and transparency stretch to other major web services as well.\nIn a hearing that lasted more than three hours, a bipartisan group of senators told executives from YouTube, Snap and TikTok that they worried the companies’ software steered young people toward inappropriate posts, mishandled consumer data and did not do enough to spot dangerous content on their platforms. Lawmakers repeatedly said their staff had been able to find harmful content — including posts related to self-harm and pornography — inside the companies’ products, sometimes while logged in as a teenage user.\nSenator Richard Blumenthal, Democrat of Connecticut, opened the hearing by accusing the companies of drawing young people further and further into their products.\n“Everything that you do is to add users, especially kids, and keep them on your apps for longer,” said Mr. Blumenthal, who leads the subcommittee of the Senate Commerce Committee that held the hearing.\nThe tough questions reflect the growing pressure for the nation’s largest social media companies to shield children who use their products from content that exposes them to violence or danger or diminishes their self-worth. The pressure has increased sharply in the last two weeks, after Frances Haugen, the former Facebook product manager who leaked thousands of pages of internal documents, told the committee how the company knew that its products made some teenagers feel worse about themselves.\nImage Lawmakers told executives that their companies did not do enough to protect children online. Credit... Oliver Contreras for The New York Times\nLawmakers have increasingly begun to discuss legislation meant to better protect children online. A group of House lawmakers have proposed a bill that would open the platforms up to litigation if their algorithms amplify content tied to severe harm. And Mr. Blumenthal suggested on Tuesday that American officials could adopt a children’s design code similar to one that recently took effect in Britain that applies new rules to how companies use children's data.\nAny new rules would have to make it through a gridlocked Congress. But child protection proposals don’t necessarily face the partisan divides that may stymie other attempts to regulate the tech giants.\n“It’s one of the few areas where Congress can actually do something and there is bipartisan consensus,” said Nu Wexler, a former communications staff member for tech companies and lawmakers in Washington. “For legislators, in some ways child safety is the path of least resistance.”\nThe companies sent executives with political experience to answer the questions. TikTok was represented by Michael Beckerman, its head of public policy for the Americas who used to lead a top lobbying group for internet companies. Leslie Miller, YouTube’s vice president for government affairs and public policy and a former Democratic political aide, appeared on behalf of the streaming site. Snap, the parent company of Snapchat, sent Jennifer Stout, its vice president for global public policy and John Kerry’s former deputy chief of staff.\nThe companies quickly tried to distance themselves from one another, while arguing they were already taking significant steps to protect child users.\nMs. Stout said Snapchat was an “antidote to social media” and stressed the differences between Snapchat and Instagram. She said her company’s app focused on connecting people who already knew each other in real life, rather than feeding them a constant stream of content from strangers. And she said it focused on privacy, making images and messages delete by default.\nShe also stressed that Snapchat moderates the public content it promotes more heavily than other social media companies. Human moderators review content from publishers before promoting it in Discover, the public section of Snapchat that contains news and entertainment, Ms. Stout said. Content on Spotlight, Snap’s creator program that promotes videos from its users, is reviewed by artificial intelligence before being distributed, and reviewed by human moderators before it can be watched by more than 25 users, Ms. Stout added.\nMr. Beckerman said that TikTok was different from other platforms that focus more on direct communication between users.\n“It’s about uplifting, entertaining content,” he said. “People love it.”\nHe said that policymakers should look at the systems that verify whether users were old enough to use a product, suggesting that legislation should include language on age verification “across apps.”\nLawmakers also hammered Mr. Beckerman about whether TikTok’s Chinese ownership could expose consumer data to Beijing. Critics have long argued that the company would be obligated to turn Americans’ data over to the Chinese government if asked.\n“Access controls for our data is done by our U.S. teams,” said Mr. Beckerman. “And as independent researchers, independent experts have pointed out, the data that TikTok has on the app is not of a national security importance and is of low sensitivity.”\nSenators repeatedly tried to prod the companies to commit to more transparency for researchers to investigate the health and safety of their platforms as well as support for elements of potential privacy legislation.\nImage Leslie Miller of YouTube sidestepped some questions from lawmakers. Credit... Oliver Contreras for The New York Times\nMs. Miller of YouTube refused to be pinned down in a series of exchanges with senators. When Mr. Blumenthal asked whether the companies would allow independent researchers access to algorithms, data sets and data privacy practices, Ms. Miller responded: “It would depend on the details, but we’re always looking to partner with experts in these important fields.”\nMr. Blumenthal shot back that YouTube’s answer “indicates certainly a strong hesitancy if not resistance to providing access.”\nSimilarly, Ms. Miller seemed reluctant to commit to aspects of potential privacy legislation such as a proposed update to the Children’s Online Privacy Protection Act. Specifically, she waffled on whether YouTube would support a ban on targeted advertising for children or curbs on adding “likes” or comments on videos — even as Ms. Miller said the company already did not permit such features on children’s content.\nThe companies frequently argued that they were already taking the kinds of steps that could be required by laws in the future.\n“We believe that regulation is necessary but given the speed at which technology develops and the rate at which regulation can be implemented, regulation alone can’t get the job done,” Ms. Stout said.\nLawmakers resisted efforts by the executives to paint their employers as the exception to concerns about children's safety online.\n“I understand from your testimony that your defense is: We’re not Facebook,” Mr. Blumenthal said. “Being different from Facebook is not a defense. That bar is in the gutter.”", "url": "https://www.nytimes.com/live/2021/10/26/business/news-business-stock-market/hong-kongs-quarantine-rules-among-the-tightest-in-world-are-getting-even-tighter"}