{"authors": ["Mae Ryan", "Cade Metz", "Rumsey Taylor"], "date_download": "2022-10-25 23:40:52", "date_modify": "2022-10-25 23:40:52", "date_publish": "2018-07-30 16:00:43", "description": "Robotic hands could only do what vast teams of engineers programmed them to do. Now they can learn more complex tasks on their own.", "filename": "interactive_2018_07_30_technology_robot-hands_1666741252.html", "image_url": "https://static01.nyt.com/images/2018/07/30/technology/robot-hands-promo/robot-hands-promo-facebookJumbo.jpg?year=2018&h=550&w=1050&s=980b9905cd717eab020d2030f2a2b3162ded2678c42b6ca7715e7d59de227a6c&k=ZQJBKqZ0VN", "language": "en", "localpath": "/Users/matthewwhite/news-please-repo//data/2022/10/25/nytimes.com/interactive_2018_07_30_technology_robot-hands_1666741252.html", "title": "How Robot Hands Are Evolving to Do What Ours Can", "title_page": "How Robot Hands Are Evolving to Do What Ours Can - The New York Times", "title_rss": "NULL", "source_domain": "nytimes.com", "maintext": "A robotic hand? Four autonomous fingers and a thumb that can do anything your own flesh and blood can do? That is still the stuff of fantasy.\nBut inside the world’s top artificial intelligence labs, researchers are getting closer to creating robotic hands that can mimic the real thing.\nThe Spinner\nInside OpenAI, the San Francisco artificial intelligence lab founded by Elon Musk and several other big Silicon Valley names, you will find a robotic hand called Dactyl. It looks a lot like Luke Skywalker’s mechanical prosthetic in the latest Star Wars film: mechanical digits that bend and straighten like a human hand.\nIf you give Dactyl an alphabet block and ask it to show you particular letters — let’s say the red O, the orange P and the blue I — it will show them to you and spin, twist and flip the toy in nimble ways.\nFor a human hand, that is a simple task. But for an autonomous machine, it is a notable achievement: Dactyl learned the task largely on its own. Using the mathematical methods that allow Dactyl to learn, researchers believe they can train robotic hands and other machines to perform far more complex tasks.\nThis remarkably nimble hand represents an enormous leap in robotic research over the last few years. Until recently, researchers were still struggling to master much simpler tasks with much simpler hands.\nThe Gripper\nCreated by researchers at the Autolab, a robotics lab inside the University of California at Berkeley, this system represents the limits of technology just a few years ago.\nEquipped with a two-fingered “gripper,” the machine can pick up items like a screwdriver or a pair of pliers and sort them into bins.\nThe gripper is much easier to control than a five-fingered hand, and building the software needed to operate a gripper is not nearly as difficult.\nIt can deal with objects that are slightly unfamiliar. It may not know what a restaurant-style ketchup bottle is, but the bottle has the same basic shape as a screwdriver — something the machine does know.\nBut when this machine is confronted with something that is different from what it has seen before — like a plastic bracelet — all bets are off.\nThe Picker\nWhat you really want is a robot that can pick up anything, even stuff it has never seen before. That is what other Autolab researchers have built over the last few years.\nThis system still uses simple hardware: a gripper and a suction cup. But it can pick up all sorts of random items, from a pair of scissors to a plastic toy dinosaur.\nThe system benefits from dramatic advances in machine learning. The Berkeley researchers modeled the physics of more than 10,000 objects, identifying the best way to pick up each one. Then, using an algorithm called a neural network, the system analyzed all this data, learning to recognize the best way to pick up any item. In the past, researchers had to program a robot to perform each task. Now it can learn these tasks on its own.\nWhen confronted with, say, a plastic Yoda toy, the system recognizes it should use the gripper to pick the toy up.\nBut when it faces the ketchup bottle, it opts for the suction cup.\nThe picker can do this with a bin full of random stuff. It is not perfect, but because the system can learn on its own, it is improving at a far faster rate than machines of the past.\nThe Bed Maker\nThis robot may not make perfect hospital corners, but it represents notable progress. Berkeley researchers pulled the system together in just two weeks, using the latest machine learning techniques. Not long ago, this would have taken months or years.\nNow the system can learn to make a bed in a fraction of that time, just by analyzing data. In this case, the system analyzes the movements that lead to a made bed.\nThe Pusher\nAcross the Berkeley campus, at a lab called BAIR, another system is applying other learning methods. It can push an object with a gripper and predict where it will go. That means it can move toys across a desk much as you or I would.\nThe system learns this behavior by analyzing vast collections of video images showing how objects get pushed. In this way, it can deal with the uncertainties and unexpected movements that come with this kind of task.\nThe Future\nThese are all simple tasks. And the machines can only handle them in certain conditions. They fail as much as they impress. But the machine learning methods that drive these systems point to continued progress in the years to come.\nLike those at OpenAI, researchers at the University of Washington are training robotic hands that have all the same digits and joints that our hands do.\nThat is far more difficult than training a gripper or suction cup. An anthropomorphic hand moves in so many different ways.\nSo, the Washington researchers train their hand in simulation -- a digital recreation of the real world. That streamlines the training process.\nAt OpenAI, researchers are training their Dactyl hand in much the same way. The system can learn to spin the alphabet block through what would have been 100 years of trial and error. The digital simulation, running across thousands of computer chips, crunches all that learning down to two days.\nIt learns these tasks by repeated trial and error. Once it learns what works in the simulation, it can apply this knowledge to the real world.\nMany researchers have questioned whether this kind of simulated training will transfer to the physical realm. But like researchers at Berkeley and other labs, the OpenAI team has shown that it can.\nThey introduce a certain amount of randomness to the simulated training. They change the friction between the hand and the block. They even change the simulated gravity. After learning to deal with this randomness in a simulated world, the hand can deal with the uncertainties of the real one.", "url": "https://www.nytimes.com/interactive/2018/07/30/technology/robot-hands.html"}